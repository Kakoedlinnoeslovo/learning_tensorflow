{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "INPUT_VEC_SIZE = 28\n",
    "TIME_STEP_SIZE = 28\n",
    "BATCH_SIZE = 128\n",
    "TEST_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "#                        O * W + b -> 10 labels for each image, O[? 28], W[28 10], B[10]\n",
    "#                       ^ (O: output 28 vec from 28 vec input)\n",
    "#                       |\n",
    "#      +-+  +-+       +--+\n",
    "#      |1|->|2|-> ... |28| time_step_size = 28\n",
    "#      +-+  +-+       +--+\n",
    "#       ^    ^    ...  ^\n",
    "#       |    |         |\n",
    "# img1:[28] [28]  ... [28]\n",
    "# img2:[28] [28]  ... [28]\n",
    "# img3:[28] [28]  ... [28]\n",
    "# ...\n",
    "# img128 or img256 (batch_size or test_size 256)\n",
    "#      each input size = input_vec_size=lstm_size=28\n",
    "\n",
    "# configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28)\n",
      "(28, 128, 28)\n",
      "(3584, 28)\n"
     ]
    }
   ],
   "source": [
    "#example 1\n",
    "a = tf.Variable(tf.random_normal((128, 28, 28), stddev=0.01))\n",
    "print(a.shape)\n",
    "a_t = tf.transpose(a, [1,0,2])\n",
    "print(a_t.shape)\n",
    "a_r = tf.reshape(a_t, [-1, 28])\n",
    "print(a_r.shape)\n",
    "\n",
    "#example 2\n",
    "\n",
    "# 'value' is a tensor with shape [5, 30]\n",
    "# Split 'value' into 3 tensors with sizes [4, 15, 11] along dimension 1\n",
    "# split0, split1, split2 = tf.split(value, [4, 15, 11], 1)\n",
    "# tf.shape(split0)  # [5, 4]\n",
    "# tf.shape(split1)  # [5, 15]\n",
    "# tf.shape(split2)  # [5, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example 3\n",
    "\n",
    "#BasicLSTMCell\n",
    "\n",
    "#lstm cell zero\n",
    "#time step zero\n",
    "#128 vectors of size 28x1\n",
    "\n",
    "#################################\n",
    "#                               #\n",
    "#                               #\n",
    "#                               #\n",
    "#                               #\n",
    "#                               #\n",
    "#                               #\n",
    "#################################\n",
    "#  ^         ^       ...     ^\n",
    "#  |         |               |\n",
    "# img1:[1] img2:[1]  ... img:128[1]\n",
    "#      [1]      [1]  ...        [1]\n",
    "#      [1]      [1]  ...        [1]\n",
    "\n",
    "\n",
    "#example 4\n",
    "#https://www.tensorflow.org/api_docs/python/tf/nn/static_rnn\n",
    "#tf.nn.static_rnn()\n",
    "# The simplest form of RNN network generated is:\n",
    "\n",
    "#   state = cell.zero_state(...)\n",
    "#   outputs = []\n",
    "#   for input_ in inputs:\n",
    "#     output, state = cell(input_, state)\n",
    "#     outputs.append(output)\n",
    "#   return (outputs, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "def model(X, W, b, input_vec_size):\n",
    "    \n",
    "    lstm_size = input_vec_size # you can choose any lstm_size, \n",
    "    #but here lstm_size = input_vec_size\n",
    "    \n",
    "    #X, input shape: (batch_size, time_step_size, input_vec_size)\n",
    "    XT = tf.transpose(X, [1,0,2])\n",
    "    #XT shape: (time_step_size, batch_size, input_vec_size)\n",
    "    XR = tf.reshape(XT, [-1, lstm_size]) #each row has input for each lstm cell\n",
    "    #XR shape: (time_step_size * batch_size, input_vec_size)\n",
    "    X_split = tf.split(XR, TIME_STEP_SIZE, 0) #split them to TIME_STEP_SIZE (28 arrays)\n",
    "    #Each array shape: (batch_size, input_vec_size)\n",
    "    # Total TIME_STEP_SIZE x (batch_size, input_vec_size)\n",
    "    \n",
    "    \n",
    "    #Make lstm with lstm_size (each input vector size),\n",
    "    # input: (None, 28 = input_vec_size)\n",
    "    lstm = tf.nn.rnn_cell.LSTMCell(lstm_size, \n",
    "                                   forget_bias = 1.0, \n",
    "                                   state_is_tuple = True)\n",
    "    \n",
    "    #Get lstm cell output, time_step_size(28) arrays with lstm_size output:\n",
    "    #(batch_size, lstm_size)\n",
    "    outputs, _states = rnn.static_rnn(lstm, \n",
    "                                      X_split, \n",
    "                                      dtype = tf.float32)\n",
    "    \n",
    "    #Linear activation \n",
    "    #Get the last output\n",
    "    return tf.matmul(outputs[-1], W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "trX = trX.reshape(-1, 28, 28)\n",
    "teX = teX.reshape(-1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 28, 28])\n",
    "Y = tf.placeholder(\"float\", [None, 10])\n",
    "\n",
    "#get lstm_size and output 10 lables\n",
    "W = get_weight([INPUT_VEC_SIZE, 10])\n",
    "b = get_weight([10])\n",
    "\n",
    "py_x = model(X, W, b, INPUT_VEC_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(logits = py_x, \n",
    "                                                        labels = Y))\n",
    "train_op = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "predict_op = tf.argmax(py_x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on step 0 is 0.66015625\n",
      "Accuracy on step 1 is 0.796875\n",
      "Accuracy on step 2 is 0.8828125\n",
      "Accuracy on step 3 is 0.90625\n",
      "Accuracy on step 4 is 0.9375\n",
      "Accuracy on step 5 is 0.93359375\n",
      "Accuracy on step 6 is 0.9375\n",
      "Accuracy on step 7 is 0.953125\n",
      "Accuracy on step 8 is 0.9296875\n",
      "Accuracy on step 9 is 0.9609375\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    for i in range(10):\n",
    "        for start, end in zip(range(0, len(trX), BATCH_SIZE),\\\n",
    "                              range(BATCH_SIZE, len(trX), BATCH_SIZE)):\n",
    "            sess.run(train_op, feed_dict = {X: trX[start:end], \n",
    "                                            Y: trY[start:end]})\n",
    "            \n",
    "        test_indeces = np.arange(len(teX))\n",
    "        np.random.shuffle(test_indeces)\n",
    "\n",
    "        batch_teX = teX[test_indeces[:TEST_SIZE]]\n",
    "        batch_teY = teY[test_indeces[:TEST_SIZE]]\n",
    "\n",
    "        pred_val = sess.run(predict_op, feed_dict = {X: batch_teX, \n",
    "                                                     Y: batch_teY})\n",
    "        Y_norm = np.argmax(batch_teY, 1)\n",
    "        accuracy_val = np.mean(pred_val == Y_norm)\n",
    "        print(\"Accuracy on step {} is {}\".format(i, accuracy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
